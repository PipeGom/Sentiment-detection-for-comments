import streamlit as st
import pandas as pd
import plotly.express as px
from collections import Counter
from wordcloud import WordCloud
import matplotlib.pyplot as plt
import re
import nltk
from nltk.corpus import stopwords
from nltk.tokenize import word_tokenize
from transformers import pipeline
import base64 # Utilizado si se quisieran incrustar im√°genes en CSS, aunque no se usa directamente aqu√≠.
import os # Importar el m√≥dulo os para manejar rutas de archivos

# --- Descargar recursos de NLTK (solo la primera vez que se ejecuta) ---
# Asegura que las stopwords y el tokenizador est√©n disponibles para el procesamiento de texto.
try:
    nltk.data.find('corpora/stopwords')
except Exception:
    nltk.download('stopwords')
try:
    nltk.data.find('tokenizers/punkt')
except Exception:
    nltk.download('punkt')
# --- A√ëADIDO: Descargar 'punkt_tab' que es necesario para word_tokenize en algunos contextos ---
try:
    nltk.data.find('tokenizers/punkt_tab')
except Exception:
    nltk.download('punkt_tab')


# --- CONFIGURACI√ìN INICIAL DE STREAMLIT ---
# Configura el dise√±o de la p√°gina a "wide" para una mejor visualizaci√≥n de los gr√°ficos.
# La barra lateral se expande por defecto.
st.set_page_config(layout="wide", page_title="An√°lisis de Opiniones de Clientes üó£Ô∏è",
                   initial_sidebar_state="expanded")

# --- CARGAR ESTILOS CSS EXTERNOS ---
# Funci√≥n para leer el archivo CSS y codificarlo en base64 para inyectarlo.
@st.cache_data
def load_css(file_name):
    with open(file_name) as f:
        st.markdown(f'<style>{f.read()}</style>', unsafe_allow_html=True)

# Carga el archivo de estilos CSS. Aseg√∫rate de que 'styles.css' est√© en la misma carpeta que 'app.py'.
load_css('./assets/styles.css')


# --- FUNCI√ìN PARA PROCESAR EL TEXTO (LIMPIEZA, TOKENIZACI√ìN, STOPWORDS) ---
def clean_text(text):
    """
    Limpia el texto: lo convierte a min√∫sculas, elimina caracteres no alfab√©ticos
    (excepto tildes y '√±') y n√∫meros.
    """
    # Asegura que el input sea string y lo convierte a min√∫sculas.
    # Si el texto es NaN (valor nulo), lo convierte a una cadena vac√≠a.
    text = str(text).lower() if pd.notna(text) else ""
    # Elimina caracteres que no sean letras (incluyendo tildes y √±) o espacios.
    # Se mantienen los n√∫meros por si son relevantes en opiniones (ej. "modelo X200").
    text = re.sub(r'[^a-zA-Z0-9√°√©√≠√≥√∫√º√±√Å√â√ç√ì√ö√ú√ë\s]', '', text)
    return text

def get_word_counts(opinions_df, text_column='opinion'):
    """
    Calcula la frecuencia de las palabras en las opiniones despu√©s de limpiar
    y eliminar las stopwords en espa√±ol.
    """
    all_words = []
    # Carga el conjunto de stopwords en espa√±ol de NLTK.
    spanish_stopwords = set(stopwords.words('spanish'))

    for opinion in opinions_df[text_column]:
        cleaned_opinion = clean_text(opinion)
        words = word_tokenize(cleaned_opinion) # Divide el texto en palabras
        # Filtra las palabras: no son stopwords y tienen m√°s de 2 caracteres.
        filtered_words = [word for word in words if word not in spanish_stopwords and len(word) > 2]
        all_words.extend(filtered_words)
    return Counter(all_words) # Retorna un contador de la frecuencia de cada palabra.

# --- MODELO DE CLASIFICACI√ìN DE SENTIMIENTOS (Hugging Face) ---
# Usa st.cache_resource para cargar el modelo solo una vez y mejorar el rendimiento
# al evitar recargas en cada interacci√≥n del usuario.
@st.cache_resource
def load_sentiment_model():
    """
    Carga un modelo de an√°lisis de sentimientos desde Hugging Face.
    El modelo 'nlptown/bert-base-multilingual-uncased-sentiment' es multiling√ºe
    y adecuado para espa√±ol.
    Para opciones m√°s ligeras, se podr√≠a explorar modelos basados en DistilBERT o TinyBERT
    entrenados para espa√±ol, aunque podr√≠an tener una menor precisi√≥n.
    """
    return pipeline("sentiment-analysis", model="nlptown/bert-base-multilingual-uncased-sentiment")

# Carga el modelo al iniciar la aplicaci√≥n.
sentiment_analyzer = load_sentiment_model()

def classify_sentiment(text):
    """
    Clasifica el sentimiento de un texto dado usando el modelo cargado.
    Mapea las etiquetas del modelo (ej. '1 star', '5 stars') a 'Positivo', 'Negativo', 'Neutro'.
    """
    # Asegura que el texto sea una cadena y no est√© vac√≠o para el an√°lisis de sentimiento.
    text_to_analyze = str(text) if pd.notna(text) and text.strip() != "" else "neutro" # Proporciona un texto por defecto si est√° vac√≠o
    
    result = sentiment_analyzer(text_to_analyze)
    sentiment_label = result[0]['label']
    
    # Mapeo de las etiquetas del modelo a las categor√≠as de sentimiento deseadas.
    if "5 stars" in sentiment_label or "4 stars" in sentiment_label:
        return "Positivo"
    elif "1 star" in sentiment_label:
        return "Negativo"
    else: # Incluye "2 stars" y "3 stars" como neutro.
        return "Neutro"

# --- MODELO PARA RESUMEN (Hugging Face) ---
@st.cache_resource
def load_summarization_model():
    """
    Carga un modelo de resumen de texto desde Hugging Face.
    'sshleifer/distilbart-cnn-12-6' es un modelo popular para res√∫menes y es una versi√≥n
    destilada de BART, lo que lo hace m√°s ligero que el modelo BART original.
    """
    return pipeline("summarization", model="sshleifer/distilbart-cnn-12-6")

summarizer = load_summarization_model()

# --- INTERFAZ DE USUARIO PRINCIPAL ---
st.title("üó£Ô∏è An√°lisis de Opiniones de Clientes")

# --- SECCI√ìN DE SUBIDA DE ARCHIVO CSV ---
st.sidebar.header("üì§ Cargar Opiniones")
uploaded_file = st.sidebar.file_uploader("Sube tu archivo CSV con opiniones (m√°x. 20)", type=["csv"])

df_opinions = pd.DataFrame() # Inicializa un DataFrame vac√≠o para las opiniones.
default_file_path = 'data/comments.csv'

if uploaded_file is not None:
    try:
        # Intenta leer el archivo CSV subido por el usuario.
        df_opinions = pd.read_csv(uploaded_file, encoding='utf-8')
        st.sidebar.success(f"‚úÖ Se cargaron {len(df_opinions)} opiniones desde el archivo subido.")

    except Exception as e:
        st.sidebar.error(f"‚ö†Ô∏è Error al leer el archivo CSV subido: {e}")
        st.sidebar.info("Aseg√∫rate de que es un CSV v√°lido y tiene una columna 'opinion'.")
        df_opinions = pd.DataFrame() # Vac√≠a el DataFrame si hay un error con el archivo subido.
elif os.path.exists(default_file_path): # Si no se subi√≥ archivo, intenta cargar el predeterminado.
    try:
        df_opinions = pd.read_csv(default_file_path, encoding='utf-8')
        st.sidebar.info(f"‚ÑπÔ∏è Se cargaron {len(df_opinions)} opiniones desde el archivo predeterminado: {default_file_path}")
    except Exception as e:
        st.sidebar.error(f"‚ö†Ô∏è Error al leer el archivo predeterminado {default_file_path}: {e}")
        st.sidebar.info("Aseg√∫rate de que el archivo existe y es un CSV v√°lido con una columna 'opinion'.")
        df_opinions = pd.DataFrame() # Vac√≠a el DataFrame si hay un error con el archivo predeterminado.
else:
    st.sidebar.warning("‚ö†Ô∏è No se ha subido ning√∫n archivo y el archivo predeterminado 'data/comments.csv' no fue encontrado.")
    st.info("‚¨ÜÔ∏è Por favor, sube un archivo CSV con opiniones para comenzar el an√°lisis o aseg√∫rate de que 'data/comments.csv' existe y es accesible.")


# --- VALIDACI√ìN Y TRUNCADO DE OPINIONES CARGADAS (ya sea subidas o predeterminadas) ---
if not df_opinions.empty:
    # Limita el n√∫mero de opiniones a 20 seg√∫n el requisito.
    if len(df_opinions) > 20:
        st.sidebar.warning("Se han cargado m√°s de 20 opiniones. Solo se usar√°n las primeras 20.")
        df_opinions = df_opinions.head(20)

    # Verifica si la columna 'opinion' existe en el DataFrame.
    if 'opinion' not in df_opinions.columns:
        st.error("‚ùå El archivo CSV (subido o predeterminado) debe contener una columna llamada 'opinion'.")
        df_opinions = pd.DataFrame() # Vac√≠a el DataFrame si el formato no es correcto.
    else:
        # Solo muestra las opiniones cargadas si el DataFrame no est√° vac√≠o y es v√°lido.
        if not df_opinions.empty:
            st.subheader("üìù Opiniones Cargadas:")
            st.dataframe(df_opinions, use_container_width=True) # Muestra las opiniones cargadas.


# --- AN√ÅLISIS DE DATOS SOLO SI SE HAN CARGADO OPINIONES V√ÅLIDAS ---
if not df_opinions.empty and 'opinion' in df_opinions.columns: # Doble verificaci√≥n para asegurar la columna
    st.markdown("---") # Separador visual.
    st.header("üìä An√°lisis de las Opiniones")

    # --- NUBE DE PALABRAS Y GR√ÅFICO DE BARRAS DE PALABRAS M√ÅS REPETIDAS ---
    st.subheader("Palabras Clave ‚ú®")
    word_counts = get_word_counts(df_opinions, text_column='opinion')

    col1, col2 = st.columns(2) # Divide la p√°gina en dos columnas para los gr√°ficos.

    with col1:
        st.markdown("##### Nube de Palabras ‚òÅÔ∏è")
        if word_counts:
            # Genera la nube de palabras a partir de las frecuencias calculadas.
            wordcloud = WordCloud(width=800, height=400, background_color='white',
                                  collocations=False, # Evita agrupar palabras que aparecen juntas.
                                  stopwords=stopwords.words('spanish') # Asegura el uso de stopwords en espa√±ol.
                                  ).generate_from_frequencies(word_counts)
            fig, ax = plt.subplots(figsize=(10, 5))
            ax.imshow(wordcloud, interpolation='bilinear')
            ax.axis("off") # Oculta los ejes del gr√°fico.
            st.pyplot(fig) # Muestra el gr√°fico en Streamlit.
        else:
            st.info("‚ÑπÔ∏è No hay palabras para generar la nube. Aseg√∫rate de que las opiniones tienen contenido.")

    with col2:
        st.markdown("##### 10 Palabras M√°s Repetidas üìà")
        if word_counts:
            top_10_words = word_counts.most_common(10) # Obtiene las 10 palabras m√°s comunes.
            df_top_words = pd.DataFrame(top_10_words, columns=['Palabra', 'Frecuencia'])
            # Crea un gr√°fico de barras interactivo con Plotly Express.
            fig_bar = px.bar(df_top_words, x='Palabra', y='Frecuencia',
                             title='Top 10 Palabras M√°s Repetidas (sin Stopwords)',
                             color_discrete_sequence=px.colors.qualitative.Pastel) # Paleta de colores.
            st.plotly_chart(fig_bar, use_container_width=True) # Muestra el gr√°fico, ajustando al ancho del contenedor.
        else:
            st.info("‚ÑπÔ∏è No hay palabras para mostrar. Aseg√∫rate de que las opiniones tienen contenido.")

    # --- CLASIFICACI√ìN DE SENTIMIENTOS ---
    st.markdown("---")
    st.subheader("Clasificaci√≥n de Sentimientos üòäüò†üòê")

    # Aplica la funci√≥n de clasificaci√≥n de sentimiento a cada opini√≥n.
    df_opinions['sentimiento'] = df_opinions['opinion'].apply(classify_sentiment)

    st.markdown("##### Sentimiento por Opini√≥n")
    st.dataframe(df_opinions[['opinion', 'sentimiento']], use_container_width=True) # Muestra la tabla.

    # Calcula el porcentaje de opiniones por cada clase de sentimiento.
    sentiment_counts = df_opinions['sentimiento'].value_counts(normalize=True) * 100
    df_sentiment_counts = sentiment_counts.reset_index()
    df_sentiment_counts.columns = ['Sentimiento', 'Porcentaje']

    # Crea un gr√°fico de pastel interactivo para visualizar los porcentajes.
    fig_pie = px.pie(df_sentiment_counts, values='Porcentaje', names='Sentimiento',
                     title='Porcentaje de Opiniones por Sentimiento',
                     color='Sentimiento',
                     # Mapeo de colores para cada sentimiento.
                     color_discrete_map={'Positivo':'#5CB85C', 'Negativo':'#D9534F', 'Neutro':'#F0AD4E'})
    st.plotly_chart(fig_pie, use_container_width=True)

    # --- INTERACCI√ìN CON MODELOS DE LENGUAJE ---
    st.markdown("---")
    st.header("ü§ñ Interacci√≥n con Modelos de Lenguaje")

    # Se elimina la opci√≥n de preguntar sobre los comentarios subidos.
    # Solo se mantiene la funcionalidad de an√°lisis de comentarios nuevos.
    st.markdown("##### Analizar un Comentario Nuevo ‚úçÔ∏è")
    new_comment = st.text_area("Escribe tu comentario aqu√≠:", height=100, help="Escribe una opini√≥n de cliente para analizar su sentimiento y obtener un resumen.")
    if st.button("Analizar Comentario Nuevo"):
        if new_comment:
            st.write(f"**Comentario Original:** {new_comment}")
            new_sentiment = classify_sentiment(new_comment)
            # Muestra el sentimiento con colores de Streamlit.
            st.write(f"**Sentimiento Detectado:** :green[{new_sentiment}]" if new_sentiment == "Positivo" else f":red[{new_sentiment}]" if new_sentiment == "Negativo" else f":orange[{new_sentiment}]")

            # Genera resumen solo si el comentario es suficientemente largo.
            num_words = len(new_comment.split())
            if num_words > 10: # Solo resumir si tiene al menos 10 palabras
                # Ajusta max_length y min_length din√°micamente
                # max_length ser√° el 75% de las palabras del input, con un m√°ximo de 150
                dynamic_max_length = min(150, int(num_words * 0.75))
                # min_length ser√° el 25% de las palabras del input, con un m√≠nimo de 10
                dynamic_min_length = max(10, int(num_words * 0.25))
                
                # Asegurarse de que min_length no sea mayor que max_length
                if dynamic_min_length > dynamic_max_length:
                    dynamic_min_length = dynamic_max_length - 5 # Asegura una diferencia m√≠nima

                try:
                    summary = summarizer(new_comment, max_length=dynamic_max_length, min_length=dynamic_min_length, do_sample=False)[0]['summary_text']
                    st.write(f"**Resumen:** {summary}")
                except Exception as e:
                    st.error(f"‚ùå Error al generar el resumen. El comentario podr√≠a ser demasiado largo o corto para el modelo. {e}")
            else:
                st.info("‚ÑπÔ∏è El comentario es demasiado corto para generar un resumen significativo.")
        else:
            st.warning("‚ö†Ô∏è Por favor, escribe un comentario para analizar.")

else:
    # Este mensaje solo se mostrar√° si no se carga ning√∫n archivo (ni subido ni predeterminado)
    # o si el archivo predeterminado no se encuentra.
    st.info("‚¨ÜÔ∏è Por favor, sube un archivo CSV con opiniones para comenzar el an√°lisis o aseg√∫rate de que 'data/comments.csv' existe y es accesible.")

